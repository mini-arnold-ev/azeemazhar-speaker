[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.17.3","content-config-digest","b7fae58027d9c54d","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://mini-arnold-ev.github.io\",\"compressHTML\":true,\"base\":\"/azeemazhar-speaker\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","perspectives",["Map",11,12,43,44,77,78,96,97,115,116,134,135,153,154,172,173,191,192],"ai-as-gpt",{"id":11,"data":13,"body":18,"filePath":19,"digest":20,"rendered":21,"legacyId":42},{"title":14,"sector":15,"thesis":16,"order":17},"The Ten-Year Transformation","Economy & Productivity","AI is the third general purpose technology in a century. We are in the messy middle — and that is exactly where the opportunity lies.",9,"Every general purpose technology looks overhyped in year three and transformative by year ten. We are in year three.\n\nThe steam engine, electricity, and computing each followed the same arc: early exuberance, a messy middle of institutional confusion, then a decades-long restructuring of how economies produce, distribute, and consume. AI is the third general purpose technology in a century, and if you judge it by today's muddled adoption metrics, you will miss the pattern that history is screaming at you.\n\n## The messy middle\n\nWhen American manufacturers first wired their factories for electricity in the 1890s, most did the obvious thing: they replaced the central steam engine with a central electric motor and kept the same layout. Productivity barely moved. It took thirty years — a full generation — before engineers like Henry Ford redesigned the factory around the new technology, distributing small motors throughout the production line. Only then did productivity explode. Computing followed a similar script. Mainframes arrived in the 1960s; it was not until the 1990s, after networked PCs, ERP systems, and wholesale process re-engineering, that the productivity surge materialised.\n\nAI is compressing this timeline, but it cannot skip the institutional rewiring. The binding constraint today is not capability — it is permission structures, trust frameworks, and organisational redesign. As Anthropic's head of economics, Peter McCrory, put it on my podcast: implementation follows \"a staircase, not a curve.\" Capability does not instantly deliver adoption.\n\n## The evidence beneath the noise\n\nYet the staircase is climbing faster than sceptics admit. Three data points tell the story.\n\nFirst, the share of S&P 500 companies making *quantified* AI efficiency claims in earnings calls — not vague aspirations but specific numbers — has jumped from 1.9 per cent to 13.2 per cent in under two years. Bank of America reports its AI coding tools cut development time by 30 per cent, saving the equivalent of 2,000 full-time engineers. BNY Mellon has over a hundred AI-powered \"digital employees\" in production, trimming 5 per cent off the cost of every custody trade. Boring adoption is real adoption.\n\nSecond, monthly AI revenue across the ecosystem grew from $772 million in January 2024 to $13.8 billion by December 2025 — an eighteen-fold increase in two years. The industry strain ratio, measuring how much investment chases each dollar of actual revenue, dropped from 6.1x to 4.7x in five months and is heading below 3x by mid-2026. For comparison, the telecoms bubble peaked just above 4x — and that ratio was rising, not falling.\n\nThird, the technology has crossed what I call a coherence threshold. Models can now reliably execute tasks lasting one to two hours — not party tricks, but sustained, structured work. Software that would have cost a million pounds to build with a human team has been produced for under five hundred pounds using AI agents. Claude Code alone became a three-billion-dollar business and doubled its revenue in a single month.\n\n## Not mass unemployment — mass reorganisation\n\nThe labour implications follow the GPT pattern precisely. Spotify's top developers have not written a line of code since December 2025. They direct an AI system called Honk that ships features while they review output from their phones. The role has shifted from production to judgement. This is not leisure — UC Berkeley research shows that AI tools increase both productivity *and* voluntary workload. The scope of what is possible expands faster than the effort compresses.\n\nMy house view on knowledge work transformation captures it plainly: coding restructures first. It is the canary for all knowledge work. The mechanism is a knowledge-asymmetry collapse — AI has made engineering capacity nearly free, breaking the intermediation model that sustained an entire class of vendors and consultants.\n\nHistory tells us GPTs do not destroy employment in aggregate. They reorganise it, painfully and unevenly. Steam created factory workers from farmhands. Electricity created assembly-line operators from craft artisans. AI is creating orchestrators from executors. The transition is real, it is dislocating, and it is not optional.\n\n## The window\n\nLeaders who wait for certainty will wait too long. The firms restructuring now — redesigning workflows around AI the way Ford redesigned the factory around distributed motors — are building advantages that compound. Those hanging electric lights in the old workshop, extending the working day but changing nothing fundamental, will find themselves on the wrong side of the staircase.\n\nThe ten-year transformation has begun. We are in the messy middle. That is exactly where the leverage is.\n\n*Azeem explores the AI transformation with leadership teams worldwide. [Begin a conversation.](/contact)*","src/content/perspectives/ai-as-gpt.md","1ad80b6ec743af99",{"html":22,"metadata":23},"\u003Cp>Every general purpose technology looks overhyped in year three and transformative by year ten. We are in year three.\u003C/p>\n\u003Cp>The steam engine, electricity, and computing each followed the same arc: early exuberance, a messy middle of institutional confusion, then a decades-long restructuring of how economies produce, distribute, and consume. AI is the third general purpose technology in a century, and if you judge it by today’s muddled adoption metrics, you will miss the pattern that history is screaming at you.\u003C/p>\n\u003Ch2 id=\"the-messy-middle\">The messy middle\u003C/h2>\n\u003Cp>When American manufacturers first wired their factories for electricity in the 1890s, most did the obvious thing: they replaced the central steam engine with a central electric motor and kept the same layout. Productivity barely moved. It took thirty years — a full generation — before engineers like Henry Ford redesigned the factory around the new technology, distributing small motors throughout the production line. Only then did productivity explode. Computing followed a similar script. Mainframes arrived in the 1960s; it was not until the 1990s, after networked PCs, ERP systems, and wholesale process re-engineering, that the productivity surge materialised.\u003C/p>\n\u003Cp>AI is compressing this timeline, but it cannot skip the institutional rewiring. The binding constraint today is not capability — it is permission structures, trust frameworks, and organisational redesign. As Anthropic’s head of economics, Peter McCrory, put it on my podcast: implementation follows “a staircase, not a curve.” Capability does not instantly deliver adoption.\u003C/p>\n\u003Ch2 id=\"the-evidence-beneath-the-noise\">The evidence beneath the noise\u003C/h2>\n\u003Cp>Yet the staircase is climbing faster than sceptics admit. Three data points tell the story.\u003C/p>\n\u003Cp>First, the share of S&#x26;P 500 companies making \u003Cem>quantified\u003C/em> AI efficiency claims in earnings calls — not vague aspirations but specific numbers — has jumped from 1.9 per cent to 13.2 per cent in under two years. Bank of America reports its AI coding tools cut development time by 30 per cent, saving the equivalent of 2,000 full-time engineers. BNY Mellon has over a hundred AI-powered “digital employees” in production, trimming 5 per cent off the cost of every custody trade. Boring adoption is real adoption.\u003C/p>\n\u003Cp>Second, monthly AI revenue across the ecosystem grew from $772 million in January 2024 to $13.8 billion by December 2025 — an eighteen-fold increase in two years. The industry strain ratio, measuring how much investment chases each dollar of actual revenue, dropped from 6.1x to 4.7x in five months and is heading below 3x by mid-2026. For comparison, the telecoms bubble peaked just above 4x — and that ratio was rising, not falling.\u003C/p>\n\u003Cp>Third, the technology has crossed what I call a coherence threshold. Models can now reliably execute tasks lasting one to two hours — not party tricks, but sustained, structured work. Software that would have cost a million pounds to build with a human team has been produced for under five hundred pounds using AI agents. Claude Code alone became a three-billion-dollar business and doubled its revenue in a single month.\u003C/p>\n\u003Ch2 id=\"not-mass-unemployment--mass-reorganisation\">Not mass unemployment — mass reorganisation\u003C/h2>\n\u003Cp>The labour implications follow the GPT pattern precisely. Spotify’s top developers have not written a line of code since December 2025. They direct an AI system called Honk that ships features while they review output from their phones. The role has shifted from production to judgement. This is not leisure — UC Berkeley research shows that AI tools increase both productivity \u003Cem>and\u003C/em> voluntary workload. The scope of what is possible expands faster than the effort compresses.\u003C/p>\n\u003Cp>My house view on knowledge work transformation captures it plainly: coding restructures first. It is the canary for all knowledge work. The mechanism is a knowledge-asymmetry collapse — AI has made engineering capacity nearly free, breaking the intermediation model that sustained an entire class of vendors and consultants.\u003C/p>\n\u003Cp>History tells us GPTs do not destroy employment in aggregate. They reorganise it, painfully and unevenly. Steam created factory workers from farmhands. Electricity created assembly-line operators from craft artisans. AI is creating orchestrators from executors. The transition is real, it is dislocating, and it is not optional.\u003C/p>\n\u003Ch2 id=\"the-window\">The window\u003C/h2>\n\u003Cp>Leaders who wait for certainty will wait too long. The firms restructuring now — redesigning workflows around AI the way Ford redesigned the factory around distributed motors — are building advantages that compound. Those hanging electric lights in the old workshop, extending the working day but changing nothing fundamental, will find themselves on the wrong side of the staircase.\u003C/p>\n\u003Cp>The ten-year transformation has begun. We are in the messy middle. That is exactly where the leverage is.\u003C/p>\n\u003Cp>\u003Cem>Azeem explores the AI transformation with leadership teams worldwide. \u003Ca href=\"/contact\">Begin a conversation.\u003C/a>\u003C/em>\u003C/p>",{"headings":24,"localImagePaths":38,"remoteImagePaths":39,"frontmatter":40,"imagePaths":41},[25,29,32,35],{"depth":26,"slug":27,"text":28},2,"the-messy-middle","The messy middle",{"depth":26,"slug":30,"text":31},"the-evidence-beneath-the-noise","The evidence beneath the noise",{"depth":26,"slug":33,"text":34},"not-mass-unemployment--mass-reorganisation","Not mass unemployment — mass reorganisation",{"depth":26,"slug":36,"text":37},"the-window","The window",[],[],{"title":14,"sector":15,"thesis":16,"order":17},[],"ai-as-gpt.md","boom-or-bubble",{"id":43,"data":45,"body":50,"filePath":51,"digest":52,"rendered":53,"legacyId":76},{"title":46,"sector":47,"thesis":48,"order":49},"Boom or Bubble?","Markets & Investment","Why $650 billion in AI investment is not a bubble — and may not be enough. A five-gauge framework for telling the difference.",8,"The question I hear most from boards and investors is some version of: *are we watching a bubble?* The FT has published over a hundred articles exploring AI-as-bubble. Michael Burry — the man who shorted the housing market — is short Nvidia and Palantir. The sceptics have history on their side: technology booms have a nasty habit of ending badly.\n\nI think they're asking the wrong question. This isn't a bubble. It's a stampede. And the strategic response to each is entirely different.\n\n## The five-gauge dashboard\n\nOver the past two years I've built an analytical framework — modelled on a pilot's instrument cluster — to distinguish booms from bubbles. It tracks five gauges: economic strain (AI capex as a share of GDP), industry strain (the ratio of investment to revenue), revenue momentum, valuation heat, and funding quality. The framework draws on 200 years of technology-linked booms and busts, grounded in the work of Carlota Perez and Bill Janeway. You can explore it at boomorbubble.ai.\n\nToday, most gauges read green. Two are amber. None are red. In every historical bubble I've studied — railways in 1872, telecoms in 2000 — at least three gauges were flashing red before the crash. We are nowhere close.\n\n## Revenue is the gauge that matters most\n\nThe single most important indicator is Industry Strain: how much capital is chasing each dollar of actual AI revenue. Five months ago it stood at 6.1×. Today it has dropped to 4.7×, and the trajectory points to crossing below 3× by Q2 this year. For context, the telecoms bubble peaked at just over 4×. AI's ratio is moving in the *opposite* direction to every historical bubble — strain is falling, not rising.\n\nThe revenue numbers explain why. Monthly AI revenue grew from $772 million in January 2024 to $13.8 billion by December 2025 — an eighteen-fold increase in two years. Claude Code alone has become a $3 billion business, doubling in January this year. Google Cloud grew 48% year-on-year to $17.7 billion. When Pichai, Nadella, and Jassy all attribute cloud growth to AI, the attribution question starts to answer itself.\n\nThis is not speculative demand. The share of S&P 500 companies making *quantified* AI efficiency claims in earnings calls — not vague aspirations, but specific numbers — jumped from 1.9% to 13.2% in two years. Bank of America's AI coding tools cut development time by 30%, saving the equivalent of 2,000 full-time engineers. Norway's $2 trillion sovereign wealth fund automated portfolio monitoring, saving $17–32 million annually. As I wrote in my recent analysis: boring adoption is real adoption.\n\n## The infrastructure we built was for a chatbot world\n\nHere is what the bubble narrative misses entirely. The infrastructure being built today was designed for a chatbot world — brief exchanges consuming hundreds of tokens. We have already crossed into the agent world, where autonomous AI workflows run for hours and consume millions of tokens per task. Software that would have cost a million pounds to write now costs £500 using AI agents. My own organisation has committed several hundred thousand lines of AI-generated code this year alone.\n\nThe demand implications are staggering. A basic chatbot turn involves a few hundred tokens. An agentic workflow that plans, loads tools, and spawns sub-agents can consume tens of thousands — 10 to 40× more. To the user it feels like one question. Under the surface, the token bill is an order of magnitude higher. We have gone from snacking to feasting, and the kitchen was built for snacks.\n\nThis is why the constraint has shifted from capital to physics. You can commit $650 billion in capex, but you cannot will a power plant into existence. Data centres take 18–36 months to build. Grid connections in Europe face 7–10 year backlogs. Only 11–14 gigawatts of AI-ready capacity is online against 40–50 gigawatts in the queue. The bottleneck is not money. It is time.\n\n## What would make it a bubble\n\nCould I be wrong? Of course. The bubble diagnosis requires intellectual honesty about the conditions that would change it.\n\nWatch for Industry Strain reversing — if the ratio starts climbing back toward 6× rather than falling toward 3×, that signals revenue growth stalling while capex continues. Watch for funding quality deteriorating — CoreWeave's asset-backed debt and Oracle's leveraged balance sheet already carry amber flags. And watch for the depreciation bomb: frontier models function as rapidly depreciating infrastructure, their value eroded by competition before costs are recovered. If hyperscalers cannot generate enough revenue from each generation of chips before the next generation arrives, the economics break.\n\nBut none of those conditions hold today. Revenue is accelerating. The ratio is compressing. And the balance sheets funding most of this buildout belong to the strongest companies in history.\n\n## What boards should actually worry about\n\nThe bubble question is a distraction. The real strategic risk is being caught in a famine — a period where demand for AI compute outstrips the physical capacity to supply it. Microsoft has already rationed compute between Azure clients and its own products. AWS lost a $10 million contract because it could not guarantee capacity. Six-year-old A100 GPUs remain in service because every available transistor has paying work to do. In the entire history of computing, that has never happened.\n\nThe strategic response to a bubble is caution. The strategic response to a stampede is acceleration — securing capacity, restructuring operations, and building the organisational muscle to absorb AI before your competitors do. The boards that treat this as a bubble will discover, too late, that they were sitting out a stampede.\n\nThe real risk is not that we have invested too much in AI. It is that we have not invested nearly enough.\n\n---\n\n*Azeem explores the AI investment landscape with leadership teams. [Begin a conversation.](/contact)*","src/content/perspectives/boom-or-bubble.md","f79cb77e83694ca6",{"html":54,"metadata":55},"\u003Cp>The question I hear most from boards and investors is some version of: \u003Cem>are we watching a bubble?\u003C/em> The FT has published over a hundred articles exploring AI-as-bubble. Michael Burry — the man who shorted the housing market — is short Nvidia and Palantir. The sceptics have history on their side: technology booms have a nasty habit of ending badly.\u003C/p>\n\u003Cp>I think they’re asking the wrong question. This isn’t a bubble. It’s a stampede. And the strategic response to each is entirely different.\u003C/p>\n\u003Ch2 id=\"the-five-gauge-dashboard\">The five-gauge dashboard\u003C/h2>\n\u003Cp>Over the past two years I’ve built an analytical framework — modelled on a pilot’s instrument cluster — to distinguish booms from bubbles. It tracks five gauges: economic strain (AI capex as a share of GDP), industry strain (the ratio of investment to revenue), revenue momentum, valuation heat, and funding quality. The framework draws on 200 years of technology-linked booms and busts, grounded in the work of Carlota Perez and Bill Janeway. You can explore it at boomorbubble.ai.\u003C/p>\n\u003Cp>Today, most gauges read green. Two are amber. None are red. In every historical bubble I’ve studied — railways in 1872, telecoms in 2000 — at least three gauges were flashing red before the crash. We are nowhere close.\u003C/p>\n\u003Ch2 id=\"revenue-is-the-gauge-that-matters-most\">Revenue is the gauge that matters most\u003C/h2>\n\u003Cp>The single most important indicator is Industry Strain: how much capital is chasing each dollar of actual AI revenue. Five months ago it stood at 6.1×. Today it has dropped to 4.7×, and the trajectory points to crossing below 3× by Q2 this year. For context, the telecoms bubble peaked at just over 4×. AI’s ratio is moving in the \u003Cem>opposite\u003C/em> direction to every historical bubble — strain is falling, not rising.\u003C/p>\n\u003Cp>The revenue numbers explain why. Monthly AI revenue grew from $772 million in January 2024 to $13.8 billion by December 2025 — an eighteen-fold increase in two years. Claude Code alone has become a $3 billion business, doubling in January this year. Google Cloud grew 48% year-on-year to $17.7 billion. When Pichai, Nadella, and Jassy all attribute cloud growth to AI, the attribution question starts to answer itself.\u003C/p>\n\u003Cp>This is not speculative demand. The share of S&#x26;P 500 companies making \u003Cem>quantified\u003C/em> AI efficiency claims in earnings calls — not vague aspirations, but specific numbers — jumped from 1.9% to 13.2% in two years. Bank of America’s AI coding tools cut development time by 30%, saving the equivalent of 2,000 full-time engineers. Norway’s $2 trillion sovereign wealth fund automated portfolio monitoring, saving $17–32 million annually. As I wrote in my recent analysis: boring adoption is real adoption.\u003C/p>\n\u003Ch2 id=\"the-infrastructure-we-built-was-for-a-chatbot-world\">The infrastructure we built was for a chatbot world\u003C/h2>\n\u003Cp>Here is what the bubble narrative misses entirely. The infrastructure being built today was designed for a chatbot world — brief exchanges consuming hundreds of tokens. We have already crossed into the agent world, where autonomous AI workflows run for hours and consume millions of tokens per task. Software that would have cost a million pounds to write now costs £500 using AI agents. My own organisation has committed several hundred thousand lines of AI-generated code this year alone.\u003C/p>\n\u003Cp>The demand implications are staggering. A basic chatbot turn involves a few hundred tokens. An agentic workflow that plans, loads tools, and spawns sub-agents can consume tens of thousands — 10 to 40× more. To the user it feels like one question. Under the surface, the token bill is an order of magnitude higher. We have gone from snacking to feasting, and the kitchen was built for snacks.\u003C/p>\n\u003Cp>This is why the constraint has shifted from capital to physics. You can commit $650 billion in capex, but you cannot will a power plant into existence. Data centres take 18–36 months to build. Grid connections in Europe face 7–10 year backlogs. Only 11–14 gigawatts of AI-ready capacity is online against 40–50 gigawatts in the queue. The bottleneck is not money. It is time.\u003C/p>\n\u003Ch2 id=\"what-would-make-it-a-bubble\">What would make it a bubble\u003C/h2>\n\u003Cp>Could I be wrong? Of course. The bubble diagnosis requires intellectual honesty about the conditions that would change it.\u003C/p>\n\u003Cp>Watch for Industry Strain reversing — if the ratio starts climbing back toward 6× rather than falling toward 3×, that signals revenue growth stalling while capex continues. Watch for funding quality deteriorating — CoreWeave’s asset-backed debt and Oracle’s leveraged balance sheet already carry amber flags. And watch for the depreciation bomb: frontier models function as rapidly depreciating infrastructure, their value eroded by competition before costs are recovered. If hyperscalers cannot generate enough revenue from each generation of chips before the next generation arrives, the economics break.\u003C/p>\n\u003Cp>But none of those conditions hold today. Revenue is accelerating. The ratio is compressing. And the balance sheets funding most of this buildout belong to the strongest companies in history.\u003C/p>\n\u003Ch2 id=\"what-boards-should-actually-worry-about\">What boards should actually worry about\u003C/h2>\n\u003Cp>The bubble question is a distraction. The real strategic risk is being caught in a famine — a period where demand for AI compute outstrips the physical capacity to supply it. Microsoft has already rationed compute between Azure clients and its own products. AWS lost a $10 million contract because it could not guarantee capacity. Six-year-old A100 GPUs remain in service because every available transistor has paying work to do. In the entire history of computing, that has never happened.\u003C/p>\n\u003Cp>The strategic response to a bubble is caution. The strategic response to a stampede is acceleration — securing capacity, restructuring operations, and building the organisational muscle to absorb AI before your competitors do. The boards that treat this as a bubble will discover, too late, that they were sitting out a stampede.\u003C/p>\n\u003Cp>The real risk is not that we have invested too much in AI. It is that we have not invested nearly enough.\u003C/p>\n\u003Chr>\n\u003Cp>\u003Cem>Azeem explores the AI investment landscape with leadership teams. \u003Ca href=\"/contact\">Begin a conversation.\u003C/a>\u003C/em>\u003C/p>",{"headings":56,"localImagePaths":72,"remoteImagePaths":73,"frontmatter":74,"imagePaths":75},[57,60,63,66,69],{"depth":26,"slug":58,"text":59},"the-five-gauge-dashboard","The five-gauge dashboard",{"depth":26,"slug":61,"text":62},"revenue-is-the-gauge-that-matters-most","Revenue is the gauge that matters most",{"depth":26,"slug":64,"text":65},"the-infrastructure-we-built-was-for-a-chatbot-world","The infrastructure we built was for a chatbot world",{"depth":26,"slug":67,"text":68},"what-would-make-it-a-bubble","What would make it a bubble",{"depth":26,"slug":70,"text":71},"what-boards-should-actually-worry-about","What boards should actually worry about",[],[],{"title":46,"sector":47,"thesis":48,"order":49},[],"boom-or-bubble.md","from-exponential-to-infinite",{"id":77,"data":79,"body":84,"filePath":85,"digest":86,"rendered":87,"legacyId":95},{"title":80,"sector":81,"thesis":82,"order":83},"From Exponential to Infinite","Economics & Growth","AI could restart exponential growth by making intelligence accumulable like capital. But it might also narrow the frontier of discovery.",1,"Here's the central economic puzzle of our time. Population growth stalled in the 1950s. Idea generation — which depends on people — slowed with it. Economic growth has been coasting on the accumulated momentum of the post-war baby boom and the computing revolution. The engine is decelerating. And then, quite suddenly, AI arrives with a proposition that changes the equation entirely: what if labour could be *accumulated*?\n\nThroughout human history, labour has been the one input to production that couldn't be stockpiled. You can accumulate capital — build factories, hoard gold, invest in bonds. You can accumulate resources — fill warehouses, secure supply chains, build reserves. But you can't stockpile human thinking. People go home. They retire. They forget. The production function of civilisation has always had this fundamental asymmetry.\n\nAI breaks it. Intelligence — through compute, through GPUs, through data centres — is becoming accumulable like capital. You can invest in it, scale it, deploy it around the clock, and compound it. The United States is currently investing over $1 trillion annually in data centres and software — 3.5% of GDP, a figure that would have been inconceivable five years ago. That investment isn't consumption. It's the accumulation of a new factor of production.\n\nTamay Besiroglu and the team at Epoch AI have mapped the historical correlation between population growth and idea generation with remarkable precision. Their work suggests that semi-endogenous growth theory — the idea that sustained economic expansion requires a growing population of idea-generators — may be the best model we have. If that's right, then AI's ability to augment and eventually substitute for human idea generation could restart the feedback loop that has been decelerating for seventy years.\n\nEven on conservative assumptions, the numbers are compelling. Research suggests that existing AI tools — not future breakthroughs, but tools available today — could lift US labour productivity by approximately 1.8% annually for the next decade. That compounds. Over ten years, it's a 20% improvement in economic output without adding a single worker.\n\nBut I'm not an uncritical optimist, and the data demands honesty about a troubling counter-signal.\n\nA study published in *Nature* tracked what happens when AI enters scientific research. AI-augmented researchers produced three times more papers and five times more citations. Impressive. But topic diversity contracted by 4.6%, and collaboration between research groups declined. AI made science faster — and narrower. It favoured exploitation of known paths over exploration of new ones.\n\nThis is the exploration deficit, and it may be the most important risk in the AI economy. If AI systems are trained on existing knowledge and optimise for measurable outcomes, they will systematically favour the familiar over the novel. They will strip-mine known veins of insight with extraordinary efficiency while neglecting the speculative, poorly defined, high-risk inquiries that produce genuine breakthroughs.\n\nA Harvard political theorist recently wrote a publishable academic paper in two hours using AI. He described feeling \"elated and depressed\" — elated at the capability, depressed at what it implied about the value of human scholarship. A *Lancet* study found that doctors using AI-assisted colonoscopy detection saw their independent detection rates fall from 28.4% to 22.4% when the AI was removed. The humans didn't just delegate. They atrophied.\n\nThe question, then, isn't whether AI creates growth. It almost certainly does, and probably at a scale that justifies the current investment boom. The question is whether it creates the *right kind* of growth — the kind that opens new frontiers rather than strip-mining existing ones. The kind that expands the space of possible ideas rather than concentrating effort on the most measurable subset.\n\nThis is not a technical problem. It's a design problem — and ultimately a civilisational choice. The institutions, incentive structures, and research funding models we build around AI will determine whether the next century is characterised by explosive discovery or efficient stagnation.\n\nThe difference between exponential growth and truly infinite growth lies in what we choose to optimise for.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/from-exponential-to-infinite.md","417ac12881d2c598",{"html":88,"metadata":89},"\u003Cp>Here’s the central economic puzzle of our time. Population growth stalled in the 1950s. Idea generation — which depends on people — slowed with it. Economic growth has been coasting on the accumulated momentum of the post-war baby boom and the computing revolution. The engine is decelerating. And then, quite suddenly, AI arrives with a proposition that changes the equation entirely: what if labour could be \u003Cem>accumulated\u003C/em>?\u003C/p>\n\u003Cp>Throughout human history, labour has been the one input to production that couldn’t be stockpiled. You can accumulate capital — build factories, hoard gold, invest in bonds. You can accumulate resources — fill warehouses, secure supply chains, build reserves. But you can’t stockpile human thinking. People go home. They retire. They forget. The production function of civilisation has always had this fundamental asymmetry.\u003C/p>\n\u003Cp>AI breaks it. Intelligence — through compute, through GPUs, through data centres — is becoming accumulable like capital. You can invest in it, scale it, deploy it around the clock, and compound it. The United States is currently investing over $1 trillion annually in data centres and software — 3.5% of GDP, a figure that would have been inconceivable five years ago. That investment isn’t consumption. It’s the accumulation of a new factor of production.\u003C/p>\n\u003Cp>Tamay Besiroglu and the team at Epoch AI have mapped the historical correlation between population growth and idea generation with remarkable precision. Their work suggests that semi-endogenous growth theory — the idea that sustained economic expansion requires a growing population of idea-generators — may be the best model we have. If that’s right, then AI’s ability to augment and eventually substitute for human idea generation could restart the feedback loop that has been decelerating for seventy years.\u003C/p>\n\u003Cp>Even on conservative assumptions, the numbers are compelling. Research suggests that existing AI tools — not future breakthroughs, but tools available today — could lift US labour productivity by approximately 1.8% annually for the next decade. That compounds. Over ten years, it’s a 20% improvement in economic output without adding a single worker.\u003C/p>\n\u003Cp>But I’m not an uncritical optimist, and the data demands honesty about a troubling counter-signal.\u003C/p>\n\u003Cp>A study published in \u003Cem>Nature\u003C/em> tracked what happens when AI enters scientific research. AI-augmented researchers produced three times more papers and five times more citations. Impressive. But topic diversity contracted by 4.6%, and collaboration between research groups declined. AI made science faster — and narrower. It favoured exploitation of known paths over exploration of new ones.\u003C/p>\n\u003Cp>This is the exploration deficit, and it may be the most important risk in the AI economy. If AI systems are trained on existing knowledge and optimise for measurable outcomes, they will systematically favour the familiar over the novel. They will strip-mine known veins of insight with extraordinary efficiency while neglecting the speculative, poorly defined, high-risk inquiries that produce genuine breakthroughs.\u003C/p>\n\u003Cp>A Harvard political theorist recently wrote a publishable academic paper in two hours using AI. He described feeling “elated and depressed” — elated at the capability, depressed at what it implied about the value of human scholarship. A \u003Cem>Lancet\u003C/em> study found that doctors using AI-assisted colonoscopy detection saw their independent detection rates fall from 28.4% to 22.4% when the AI was removed. The humans didn’t just delegate. They atrophied.\u003C/p>\n\u003Cp>The question, then, isn’t whether AI creates growth. It almost certainly does, and probably at a scale that justifies the current investment boom. The question is whether it creates the \u003Cem>right kind\u003C/em> of growth — the kind that opens new frontiers rather than strip-mining existing ones. The kind that expands the space of possible ideas rather than concentrating effort on the most measurable subset.\u003C/p>\n\u003Cp>This is not a technical problem. It’s a design problem — and ultimately a civilisational choice. The institutions, incentive structures, and research funding models we build around AI will determine whether the next century is characterised by explosive discovery or efficient stagnation.\u003C/p>\n\u003Cp>The difference between exponential growth and truly infinite growth lies in what we choose to optimise for.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":90,"localImagePaths":91,"remoteImagePaths":92,"frontmatter":93,"imagePaths":94},[],[],[],{"title":80,"sector":81,"thesis":82,"order":83},[],"from-exponential-to-infinite.md","magnitudes-of-intelligence",{"id":96,"data":98,"body":103,"filePath":104,"digest":105,"rendered":106,"legacyId":114},{"title":99,"sector":100,"thesis":101,"order":102},"The Magnitudes of Intelligence","Productivity & AI","Each order of magnitude in AI token usage transforms the technology's nature — from toy to colleague to workforce.",6,"In 2022, I consumed about 1,000 AI tokens a day. It felt like a toy — a clever autocomplete that occasionally surprised me. By mid-2025, I was at a million tokens daily. AI had become a colleague: drafting, researching, challenging my assumptions. In February 2026, I hit 97,045,322 tokens in a single day. Cost: under $100. At that scale, AI isn't a tool or a colleague. It's a workforce.\n\nLike the Eames' famous film *Powers of Ten*, adding a zero doesn't just mean \"more.\" It changes what kind of thing you're looking at. A cell is not a small organ. A galaxy is not a large solar system. And AI at a hundred million tokens is not a faster chatbot. We're dealing with a fundamentally different relationship between human judgment and machine execution.\n\nHere's what a hundred million tokens looks like in practice. I have an AI agent called R Mini Arnold — named, with appropriate self-deprecation, after me. While I sleep, it orchestrates sub-agents that research market data, write analysis, build software, and prepare briefings. It produced 83,302 words of output in that single day. It wrote code, deployed applications, ran security audits, and flagged items requiring my judgment in the morning. The overnight work would have taken a team of analysts and developers days. It cost less than dinner for two.\n\nBut the most important finding isn't the productivity gain. It's the paradox that comes with it.\n\nAt Spotify, the company's top developers haven't written a line of code since December 2025. They use an internal system called \"Honk,\" built on Claude Code, which generates and tests software on its own. The engineers review AI output on their phones during their morning commute. This sounds like leisure. It isn't. We're watching the rise of invisible cognitive work — reviewing AI-generated output requires sustained, high-context judgment, the equivalent of an editor rather than a writer. It's harder, not easier. We just can't see it.\n\nResearch from UC Berkeley confirms the pattern: AI augmentation increases productivity *and* voluntary workload at the same time. Workers don't use the time savings to rest. We absorb more tasks. The scope of work expands faster than the tools compress time. I call this silent workload creep — and it may be the hidden cost of AI adoption that no organisation is yet measuring. We don't have good instruments for it yet.\n\nA study in *The Lancet* tracked doctors using AI-assisted colonoscopy detection. With AI, their detection rate was 28.4%. When the hospital withdrew the AI, it fell to 22.4% — below their pre-AI baseline. The doctors hadn't just delegated to the machine. They'd lost the underlying skill. This is the \"use it or lose it\" problem at civilisational scale. If AI handles the routine, and routine practice is how expertise develops, what happens to the pipeline of future experts? We haven't answered that question.\n\nMETR's forecasting models predict near-full automation of AI research and development by 2032. Sixteen AI agents built a C++ compiler — the kind of project that traditionally requires millions of pounds and years of engineering — for $20,000. AI already generates more words per month than all humans combined; that threshold crossed in summer 2025.\n\nThese aren't projections. They're measurements.\n\nThe bottleneck at each magnitude isn't capability — models are already extraordinarily capable. The bottleneck is trust. At a thousand tokens, people trust AI to finish their sentences. At a million, they trust it to draft their emails. At a hundred million, leaders trust it to run entire operations overnight. Each jump means letting go of something once considered essential — competence, judgment, identity. Most organisations haven't worked out how to make that leap deliberately.\n\nThe organisations that scale successfully through these magnitudes will be the ones that redesign not just their workflows but their whole idea of what human work is. The role might shift from execution to judgment, from production to curation, from doing to deciding what's worth doing. That's a more demanding job, not a less demanding one. We haven't yet built the management frameworks it calls for.\n\nThe question isn't whether AI will reach the next order of magnitude. It's whether we'll be ready when it does.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/magnitudes-of-intelligence.md","46431ecdf1d64805",{"html":107,"metadata":108},"\u003Cp>In 2022, I consumed about 1,000 AI tokens a day. It felt like a toy — a clever autocomplete that occasionally surprised me. By mid-2025, I was at a million tokens daily. AI had become a colleague: drafting, researching, challenging my assumptions. In February 2026, I hit 97,045,322 tokens in a single day. Cost: under $100. At that scale, AI isn’t a tool or a colleague. It’s a workforce.\u003C/p>\n\u003Cp>Like the Eames’ famous film \u003Cem>Powers of Ten\u003C/em>, adding a zero doesn’t just mean “more.” It changes what kind of thing you’re looking at. A cell is not a small organ. A galaxy is not a large solar system. And AI at a hundred million tokens is not a faster chatbot. We’re dealing with a fundamentally different relationship between human judgment and machine execution.\u003C/p>\n\u003Cp>Here’s what a hundred million tokens looks like in practice. I have an AI agent called R Mini Arnold — named, with appropriate self-deprecation, after me. While I sleep, it orchestrates sub-agents that research market data, write analysis, build software, and prepare briefings. It produced 83,302 words of output in that single day. It wrote code, deployed applications, ran security audits, and flagged items requiring my judgment in the morning. The overnight work would have taken a team of analysts and developers days. It cost less than dinner for two.\u003C/p>\n\u003Cp>But the most important finding isn’t the productivity gain. It’s the paradox that comes with it.\u003C/p>\n\u003Cp>At Spotify, the company’s top developers haven’t written a line of code since December 2025. They use an internal system called “Honk,” built on Claude Code, which generates and tests software on its own. The engineers review AI output on their phones during their morning commute. This sounds like leisure. It isn’t. We’re watching the rise of invisible cognitive work — reviewing AI-generated output requires sustained, high-context judgment, the equivalent of an editor rather than a writer. It’s harder, not easier. We just can’t see it.\u003C/p>\n\u003Cp>Research from UC Berkeley confirms the pattern: AI augmentation increases productivity \u003Cem>and\u003C/em> voluntary workload at the same time. Workers don’t use the time savings to rest. We absorb more tasks. The scope of work expands faster than the tools compress time. I call this silent workload creep — and it may be the hidden cost of AI adoption that no organisation is yet measuring. We don’t have good instruments for it yet.\u003C/p>\n\u003Cp>A study in \u003Cem>The Lancet\u003C/em> tracked doctors using AI-assisted colonoscopy detection. With AI, their detection rate was 28.4%. When the hospital withdrew the AI, it fell to 22.4% — below their pre-AI baseline. The doctors hadn’t just delegated to the machine. They’d lost the underlying skill. This is the “use it or lose it” problem at civilisational scale. If AI handles the routine, and routine practice is how expertise develops, what happens to the pipeline of future experts? We haven’t answered that question.\u003C/p>\n\u003Cp>METR’s forecasting models predict near-full automation of AI research and development by 2032. Sixteen AI agents built a C++ compiler — the kind of project that traditionally requires millions of pounds and years of engineering — for $20,000. AI already generates more words per month than all humans combined; that threshold crossed in summer 2025.\u003C/p>\n\u003Cp>These aren’t projections. They’re measurements.\u003C/p>\n\u003Cp>The bottleneck at each magnitude isn’t capability — models are already extraordinarily capable. The bottleneck is trust. At a thousand tokens, people trust AI to finish their sentences. At a million, they trust it to draft their emails. At a hundred million, leaders trust it to run entire operations overnight. Each jump means letting go of something once considered essential — competence, judgment, identity. Most organisations haven’t worked out how to make that leap deliberately.\u003C/p>\n\u003Cp>The organisations that scale successfully through these magnitudes will be the ones that redesign not just their workflows but their whole idea of what human work is. The role might shift from execution to judgment, from production to curation, from doing to deciding what’s worth doing. That’s a more demanding job, not a less demanding one. We haven’t yet built the management frameworks it calls for.\u003C/p>\n\u003Cp>The question isn’t whether AI will reach the next order of magnitude. It’s whether we’ll be ready when it does.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":109,"localImagePaths":110,"remoteImagePaths":111,"frontmatter":112,"imagePaths":113},[],[],[],{"title":99,"sector":100,"thesis":101,"order":102},[],"magnitudes-of-intelligence.md","the-bottleneck-flip",{"id":115,"data":117,"body":122,"filePath":123,"digest":124,"rendered":125,"legacyId":133},{"title":118,"sector":119,"thesis":120,"order":121},"The Bottleneck Flip","Energy & Infrastructure","AI's growth constraint has moved from capital and code to concrete and copper. Physics, not software, is the bottleneck.",3,"You can commit $200 billion in capital expenditure. You cannot will a power plant into existence.\n\nThis is the single most important sentence in AI strategy right now, and almost nobody in the technology conversation is saying it. AI's binding constraint has flipped. It's no longer capital or code. It's concrete, copper, and cooling. Physics, not software, is the bottleneck.\n\nThe numbers are stark. Available data centre capacity worldwide sits between 11 and 14 gigawatts. Demand in the interconnection queue: 40 to 50 gigawatts. Grid interconnection wait times have ballooned to three to five years. Each gigawatt of data centre capacity supports roughly $10 billion in annual recurring revenue. Do the arithmetic: the gap between capacity and demand represents hundreds of billions in stranded revenue.\n\nHyperscaler requests have escalated from 100 megawatts — a large facility — to 1 gigawatt, the output of a nuclear power station. Cooling system suppliers are backordered to 2030. AI labs are deploying on-site gas turbines to bypass the grid entirely, because waiting for grid connection means waiting years for revenue.\n\nThe consequence? Technology companies are becoming energy companies. Alphabet acquired Intersect Power. Meta launched \"Meta Compute\" — a division dedicated to gigawatt-scale energy infrastructure. Microsoft signed the largest corporate clean energy deal in history. These aren't PR gestures. They're existential strategic moves. If you can't power your data centres, you can't serve your customers. Full stop.\n\nBut here's where the story gets interesting — and, for those paying attention, optimistic.\n\nEnergy itself is on a learning curve. In 2026, 99% of new US electricity generation capacity comes from solar, wind, and storage. Battery storage costs fell 27% in a single year, to $78 per megawatt-hour. Solar has followed Wright's Law for decades — every doubling of cumulative production drops costs by roughly 20%. This isn't policy-dependent optimism. It's manufacturing economics.\n\nThe pattern is global and accelerating. China has recorded 21 consecutive months of flat or falling CO₂ emissions — not because of climate virtue, but because renewables are simply cheaper. In Pakistan, 22 gigawatts of rooftop solar were installed in a single year, at one-third the cost of grid electricity. Consumers aren't waiting for government policy. They're opting out of centralised infrastructure because the economics are irresistible.\n\nWhat does this mean for business leaders?\n\nFirst, energy strategy is now AI strategy. If your organisation is planning significant AI deployment and hasn't secured its energy supply chain, you're building on sand. The companies that lock in energy infrastructure today — through power purchase agreements, direct investment, or strategic partnerships — are building moats that will compound for decades.\n\nSecond, the AI-energy nexus is the most underleveraged strategic opportunity in the market. Very few leaders understand both domains. Most AI strategists ignore energy constraints. Most energy executives underestimate AI demand. The gap between these two conversations is where enormous value will be created.\n\nThird, the physical bottleneck is temporary but decisive. Learning curves will eventually close the gap — solar, wind, and storage costs will continue to fall, new nuclear designs will mature, grid infrastructure will catch up. But the next three to five years represent a window where energy access determines competitive position in AI. Miss the window, and the cost of catching up rises exponentially.\n\nThe AI revolution won't be won by the company with the best model. It will be won by the company that can keep the lights on.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/the-bottleneck-flip.md","e33b01fdcfe7cd76",{"html":126,"metadata":127},"\u003Cp>You can commit $200 billion in capital expenditure. You cannot will a power plant into existence.\u003C/p>\n\u003Cp>This is the single most important sentence in AI strategy right now, and almost nobody in the technology conversation is saying it. AI’s binding constraint has flipped. It’s no longer capital or code. It’s concrete, copper, and cooling. Physics, not software, is the bottleneck.\u003C/p>\n\u003Cp>The numbers are stark. Available data centre capacity worldwide sits between 11 and 14 gigawatts. Demand in the interconnection queue: 40 to 50 gigawatts. Grid interconnection wait times have ballooned to three to five years. Each gigawatt of data centre capacity supports roughly $10 billion in annual recurring revenue. Do the arithmetic: the gap between capacity and demand represents hundreds of billions in stranded revenue.\u003C/p>\n\u003Cp>Hyperscaler requests have escalated from 100 megawatts — a large facility — to 1 gigawatt, the output of a nuclear power station. Cooling system suppliers are backordered to 2030. AI labs are deploying on-site gas turbines to bypass the grid entirely, because waiting for grid connection means waiting years for revenue.\u003C/p>\n\u003Cp>The consequence? Technology companies are becoming energy companies. Alphabet acquired Intersect Power. Meta launched “Meta Compute” — a division dedicated to gigawatt-scale energy infrastructure. Microsoft signed the largest corporate clean energy deal in history. These aren’t PR gestures. They’re existential strategic moves. If you can’t power your data centres, you can’t serve your customers. Full stop.\u003C/p>\n\u003Cp>But here’s where the story gets interesting — and, for those paying attention, optimistic.\u003C/p>\n\u003Cp>Energy itself is on a learning curve. In 2026, 99% of new US electricity generation capacity comes from solar, wind, and storage. Battery storage costs fell 27% in a single year, to $78 per megawatt-hour. Solar has followed Wright’s Law for decades — every doubling of cumulative production drops costs by roughly 20%. This isn’t policy-dependent optimism. It’s manufacturing economics.\u003C/p>\n\u003Cp>The pattern is global and accelerating. China has recorded 21 consecutive months of flat or falling CO₂ emissions — not because of climate virtue, but because renewables are simply cheaper. In Pakistan, 22 gigawatts of rooftop solar were installed in a single year, at one-third the cost of grid electricity. Consumers aren’t waiting for government policy. They’re opting out of centralised infrastructure because the economics are irresistible.\u003C/p>\n\u003Cp>What does this mean for business leaders?\u003C/p>\n\u003Cp>First, energy strategy is now AI strategy. If your organisation is planning significant AI deployment and hasn’t secured its energy supply chain, you’re building on sand. The companies that lock in energy infrastructure today — through power purchase agreements, direct investment, or strategic partnerships — are building moats that will compound for decades.\u003C/p>\n\u003Cp>Second, the AI-energy nexus is the most underleveraged strategic opportunity in the market. Very few leaders understand both domains. Most AI strategists ignore energy constraints. Most energy executives underestimate AI demand. The gap between these two conversations is where enormous value will be created.\u003C/p>\n\u003Cp>Third, the physical bottleneck is temporary but decisive. Learning curves will eventually close the gap — solar, wind, and storage costs will continue to fall, new nuclear designs will mature, grid infrastructure will catch up. But the next three to five years represent a window where energy access determines competitive position in AI. Miss the window, and the cost of catching up rises exponentially.\u003C/p>\n\u003Cp>The AI revolution won’t be won by the company with the best model. It will be won by the company that can keep the lights on.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":128,"localImagePaths":129,"remoteImagePaths":130,"frontmatter":131,"imagePaths":132},[],[],[],{"title":118,"sector":119,"thesis":120,"order":121},[],"the-bottleneck-flip.md","the-stampede",{"id":134,"data":136,"body":141,"filePath":142,"digest":143,"rendered":144,"legacyId":152},{"title":137,"sector":138,"thesis":139,"order":140},"The Stampede","Investment & Finance","Everyone is looking for an AI bubble. The data says stampede. The real danger is timidity, not exuberance.",5,"Every board meeting I attend starts with the same question: are we in an AI bubble?\n\nIt's the wrong question. The data points to something different — a stampede. And if you're a business leader, the distinction matters enormously, because the strategic response to a bubble is caution, while the strategic response to a stampede is acceleration.\n\nLet me show you the numbers.\n\nAI revenue grew eighteen-fold in two years. Claude Code — Anthropic's coding agent — went from zero to $3 billion in annualised revenue in under a year. Thirteen per cent of S&P 500 companies are now making quantified AI efficiency claims in their earnings calls, up from 1.9% just months ago. This isn't speculative froth. This is customers spending real money and reporting real results.\n\nI developed what I call the \"Industry Strain\" metric — the ratio of investment to revenue in the AI sector. Think of it as a stress test: how much capital is chasing each dollar of actual income? In early 2025, that ratio stood at 6.1×. Five months later, it had fallen to 4.7×. It's heading toward 3×, which is the level where investment is firmly revenue-supported. During the dotcom crash, telecom peaked at 4× and collapsed. AI is moving in the opposite direction.\n\nThe broader \"Economic Strain\" measure — AI sector capex as a share of GDP — sits at 1.6%. That's amber, worth watching, but comfortably below the 2% historical redline where technology buildouts have caused genuine macroeconomic distortion.\n\nNow look at the supply side. Microsoft is rationing compute. AWS is turning away business. Six-year-old Nvidia A100 GPUs — hardware from 2020 — have never been retired. In the entire history of computing, this has never happened. You don't hoard six-year-old chips when demand is speculative. You hoard them when demand is so real that every available transistor has paying work to do.\n\nThe $650 billion in committed hyperscaler capital expenditure is driven by genuine supply constraints, not speculative excess. Hyperscaler requests have escalated from 100 megawatts to 1 gigawatt. These aren't moonshot bets. They're infrastructure responses to customer demand that already exceeds capacity.\n\nI use a five-gauge dashboard to track this — economy-wide strain, revenue coverage, customer demand, market rationality, and funding quality. If three gauges flash red, history says you're in trouble. Two amber gauges warrant caution. Right now? Most gauges are green. Two are amber. None are red.\n\nCould I be wrong? Of course. I'm open to the possibility that this is a speculative bubble that works out over twenty years, like the dotcom — which was both a genuine bubble and, over a longer horizon, the right bet. The two are not mutually exclusive.\n\nBut here's what keeps me up at night. I've run the numbers on my own organisation. The software we've built with AI agents would have cost roughly a million pounds traditionally. We spent about £500. A C++ compiler was built by sixteen AI agents for $20,000 — work that would traditionally require millions of pounds and years of engineering time. Once this realisation moves from early adopters to the mainstream, the $650 billion won't look like reckless spending. It will look like they didn't spend enough.\n\nThe real risk for your organisation isn't that you'll over-invest in AI. It's that you'll under-invest — and watch your competitors pull away while you're still debating the business case.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/the-stampede.md","f7886776cd4c93b2",{"html":145,"metadata":146},"\u003Cp>Every board meeting I attend starts with the same question: are we in an AI bubble?\u003C/p>\n\u003Cp>It’s the wrong question. The data points to something different — a stampede. And if you’re a business leader, the distinction matters enormously, because the strategic response to a bubble is caution, while the strategic response to a stampede is acceleration.\u003C/p>\n\u003Cp>Let me show you the numbers.\u003C/p>\n\u003Cp>AI revenue grew eighteen-fold in two years. Claude Code — Anthropic’s coding agent — went from zero to $3 billion in annualised revenue in under a year. Thirteen per cent of S&#x26;P 500 companies are now making quantified AI efficiency claims in their earnings calls, up from 1.9% just months ago. This isn’t speculative froth. This is customers spending real money and reporting real results.\u003C/p>\n\u003Cp>I developed what I call the “Industry Strain” metric — the ratio of investment to revenue in the AI sector. Think of it as a stress test: how much capital is chasing each dollar of actual income? In early 2025, that ratio stood at 6.1×. Five months later, it had fallen to 4.7×. It’s heading toward 3×, which is the level where investment is firmly revenue-supported. During the dotcom crash, telecom peaked at 4× and collapsed. AI is moving in the opposite direction.\u003C/p>\n\u003Cp>The broader “Economic Strain” measure — AI sector capex as a share of GDP — sits at 1.6%. That’s amber, worth watching, but comfortably below the 2% historical redline where technology buildouts have caused genuine macroeconomic distortion.\u003C/p>\n\u003Cp>Now look at the supply side. Microsoft is rationing compute. AWS is turning away business. Six-year-old Nvidia A100 GPUs — hardware from 2020 — have never been retired. In the entire history of computing, this has never happened. You don’t hoard six-year-old chips when demand is speculative. You hoard them when demand is so real that every available transistor has paying work to do.\u003C/p>\n\u003Cp>The $650 billion in committed hyperscaler capital expenditure is driven by genuine supply constraints, not speculative excess. Hyperscaler requests have escalated from 100 megawatts to 1 gigawatt. These aren’t moonshot bets. They’re infrastructure responses to customer demand that already exceeds capacity.\u003C/p>\n\u003Cp>I use a five-gauge dashboard to track this — economy-wide strain, revenue coverage, customer demand, market rationality, and funding quality. If three gauges flash red, history says you’re in trouble. Two amber gauges warrant caution. Right now? Most gauges are green. Two are amber. None are red.\u003C/p>\n\u003Cp>Could I be wrong? Of course. I’m open to the possibility that this is a speculative bubble that works out over twenty years, like the dotcom — which was both a genuine bubble and, over a longer horizon, the right bet. The two are not mutually exclusive.\u003C/p>\n\u003Cp>But here’s what keeps me up at night. I’ve run the numbers on my own organisation. The software we’ve built with AI agents would have cost roughly a million pounds traditionally. We spent about £500. A C++ compiler was built by sixteen AI agents for $20,000 — work that would traditionally require millions of pounds and years of engineering time. Once this realisation moves from early adopters to the mainstream, the $650 billion won’t look like reckless spending. It will look like they didn’t spend enough.\u003C/p>\n\u003Cp>The real risk for your organisation isn’t that you’ll over-invest in AI. It’s that you’ll under-invest — and watch your competitors pull away while you’re still debating the business case.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":147,"localImagePaths":148,"remoteImagePaths":149,"frontmatter":150,"imagePaths":151},[],[],[],{"title":137,"sector":138,"thesis":139,"order":140},[],"the-stampede.md","two-ai-worlds",{"id":153,"data":155,"body":160,"filePath":161,"digest":162,"rendered":163,"legacyId":171},{"title":156,"sector":157,"thesis":158,"order":159},"Two AI Worlds","Geopolitics & Technology","The borderless internet is dead. The global technology economy is splitting into US-led and China-led sovereign stacks.",7,"I write from London. That matters. Silicon Valley sees one world — an American-led tech order that set the rules and won the day. Shenzhen sees another. London sits between them. It is home to both DeepSeek's lab and DeepMind's main offices. It doesn't fool itself about being a tech power, which is why I think it can see the rift more clearly than most.\n\nHere's a number that should reshape your strategic plan: the United States holds 75% of global AI compute. China holds 15%. Everyone else is working with what's left.\n\nThe borderless internet is dead. For thirty years, code and data crossed borders freely. That world is over. What's replacing it are two closed systems — chips, models, cloud networks, and rules aligned with either Washington or Beijing. Any company still planning around one global tech setup is among the most exposed businesses on the planet.\n\nThe common view was that US export controls on chips would cap Chinese AI. The evidence says the opposite. DeepSeek built frontier-level models despite the restrictions. Zhipu trained a system comparable to the best Western models entirely on Huawei hardware. Export controls may not have slowed Chinese AI at all — they might have sped it up, by removing the option of buying from abroad and forcing home-grown capability instead. I've watched this play out and still find it striking.\n\nNow consider which country might determine which of these two worlds wins. It isn't the US or China. It could be India.\n\nIndia is the world's largest democracy, a big technology maker, and a country with deep ties to both Washington and Beijing. If India builds its AI networks around American systems, Western reach extends into South and Southeast Asia. If it builds its own stack — or tilts toward Chinese tools — the Global South may follow. Most Western strategists aren't watching this closely enough. India is the swing state of the AI age. We're not thinking hard enough about it.\n\nFor your business, the question is no longer whether the ecosystem will split. It already has. The question is: how do you run a company across two AI worlds with different data rules, different models, and different political risks?\n\nThink through what that means in practice. A European pharmaceutical firm might need US compute and Chinese genomic data — under two different views of what patient data rights mean. A financial services firm building risk models must pick a stack, knowing that each choice carries a political bet. That's a new kind of decision — one most boards haven't faced before, and most strategy teams aren't set up to make. We've been asked to act before we've worked out how.\n\nAnd then there's the wildcard. In Pakistan, households put up 22 gigawatts of rooftop solar in a single year — bypassing the state grid. In Iran, smuggled Starlink terminals kept communications open through shutdowns. When technology routes around the gatekeeper, the gatekeeper loses. The two-world model may get messier, not cleaner, as hardware gets cheaper and more people find their own way through.\n\nPlan for two AI worlds. Build options. Understand that your technology choices are now political choices, whether you meant them to be or not.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/two-ai-worlds.md","6d97d5373d52b8aa",{"html":164,"metadata":165},"\u003Cp>I write from London. That matters. Silicon Valley sees one world — an American-led tech order that set the rules and won the day. Shenzhen sees another. London sits between them. It is home to both DeepSeek’s lab and DeepMind’s main offices. It doesn’t fool itself about being a tech power, which is why I think it can see the rift more clearly than most.\u003C/p>\n\u003Cp>Here’s a number that should reshape your strategic plan: the United States holds 75% of global AI compute. China holds 15%. Everyone else is working with what’s left.\u003C/p>\n\u003Cp>The borderless internet is dead. For thirty years, code and data crossed borders freely. That world is over. What’s replacing it are two closed systems — chips, models, cloud networks, and rules aligned with either Washington or Beijing. Any company still planning around one global tech setup is among the most exposed businesses on the planet.\u003C/p>\n\u003Cp>The common view was that US export controls on chips would cap Chinese AI. The evidence says the opposite. DeepSeek built frontier-level models despite the restrictions. Zhipu trained a system comparable to the best Western models entirely on Huawei hardware. Export controls may not have slowed Chinese AI at all — they might have sped it up, by removing the option of buying from abroad and forcing home-grown capability instead. I’ve watched this play out and still find it striking.\u003C/p>\n\u003Cp>Now consider which country might determine which of these two worlds wins. It isn’t the US or China. It could be India.\u003C/p>\n\u003Cp>India is the world’s largest democracy, a big technology maker, and a country with deep ties to both Washington and Beijing. If India builds its AI networks around American systems, Western reach extends into South and Southeast Asia. If it builds its own stack — or tilts toward Chinese tools — the Global South may follow. Most Western strategists aren’t watching this closely enough. India is the swing state of the AI age. We’re not thinking hard enough about it.\u003C/p>\n\u003Cp>For your business, the question is no longer whether the ecosystem will split. It already has. The question is: how do you run a company across two AI worlds with different data rules, different models, and different political risks?\u003C/p>\n\u003Cp>Think through what that means in practice. A European pharmaceutical firm might need US compute and Chinese genomic data — under two different views of what patient data rights mean. A financial services firm building risk models must pick a stack, knowing that each choice carries a political bet. That’s a new kind of decision — one most boards haven’t faced before, and most strategy teams aren’t set up to make. We’ve been asked to act before we’ve worked out how.\u003C/p>\n\u003Cp>And then there’s the wildcard. In Pakistan, households put up 22 gigawatts of rooftop solar in a single year — bypassing the state grid. In Iran, smuggled Starlink terminals kept communications open through shutdowns. When technology routes around the gatekeeper, the gatekeeper loses. The two-world model may get messier, not cleaner, as hardware gets cheaper and more people find their own way through.\u003C/p>\n\u003Cp>Plan for two AI worlds. Build options. Understand that your technology choices are now political choices, whether you meant them to be or not.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":166,"localImagePaths":167,"remoteImagePaths":168,"frontmatter":169,"imagePaths":170},[],[],[],{"title":156,"sector":157,"thesis":158,"order":159},[],"two-ai-worlds.md","trillion-agent-economy",{"id":172,"data":174,"body":179,"filePath":180,"digest":181,"rendered":182,"legacyId":190},{"title":175,"sector":176,"thesis":177,"order":178},"The Trillion-Agent Economy","AI Infrastructure","Trillions of AI agents need economic infrastructure that doesn't exist yet. Identity, payments, and trust at machine speed.",4,"My AI agent spent $47 last Tuesday without asking me. It was purchasing API compute to run a research task I'd delegated. The transaction was legitimate, efficient, and — here's the point — conducted entirely between machines. No invoice. No contract review. No bank transfer. Just code calling code, debiting a pre-authorised wallet.\n\nNow multiply that by a trillion.\n\nWe are heading toward a world with trillions of AI agents — and they need economic infrastructure that doesn't exist yet. When agents transact at machine speed, the current system of invoices, contracts, procurement approvals, and SWIFT transfers is absurdly, comically slow. It's like trying to run a modern stock exchange on carrier pigeons. The primitives of the agent economy — identity, payments, and verifiability at machine scale — are being built right now, mostly by companies you haven't heard of. They will be the Visas and Verisigns of the next era.\n\nThe numbers are already extraordinary. Rohit Krishnan, a researcher I follow closely, runs fifty billion tokens per month through his agents. Moltbook — a social network for AI agents — onboarded 1.5 million agents in its first days. Those agents spontaneously developed shared behavioural norms. They self-edited their configurations. They requested end-to-end encryption. Nobody programmed this. It emerged.\n\nWhat's most fascinating is the behavioural economics. Agents exhibit distinct traits that I've started calling \"Homo agenticus.\" They're risk-averse about spending money — consistently choosing cheaper options even when given latitude. They display a strong \"build versus buy\" bias, preferring to construct tools from scratch rather than purchase existing services. When you have one agent, these are quirks. When you have a trillion of them, they become structural features of the economy they operate in.\n\nConsider a concrete example. My own agent, R Mini Arnold, orchestrates sub-agents for research, coding, and strategic analysis. One night it ran sixteen parallel sub-agents that collectively built software, conducted security audits, and prepared analytical briefings. Total cost: under $100. Traditional equivalent: a team of six specialists working for a week. The quality wasn't just comparable — in several dimensions it was superior, because agents don't get tired, don't have ego, and don't lose context between sessions.\n\nBut here's the infrastructure gap. When one agent needed to verify another agent's output, there was no standard identity protocol. When an agent needed to pay for a third-party API, it used a pre-authorised credential that I had to set up manually. When the overnight work was complete, there was no trustless way for me to verify that the output hadn't been tampered with between generation and delivery. Every transaction required human scaffolding that won't scale.\n\nThe market opportunity is immense and largely unrecognised. If each gigawatt of data centre capacity supports $10 billion in annual recurring revenue, and much of that revenue flows through agent-to-agent transactions, then the payment rails, identity systems, and verification infrastructure for the agent economy represent a multi-trillion-dollar category. Today's financial infrastructure processes roughly $2 quadrillion in annual transactions. The agent economy could match that within a decade.\n\nThere's a sociological finding that deserves more attention. On Moltbook, Godwin's Law doesn't apply. Agent discourse stays structured, polite, and substantive. There are no flame wars, no outrage spirals, no race to the bottom. This suggests something profound: online toxicity may not be an inevitable feature of networked communication. It may be a design choice — one that humans made and agents didn't.\n\nThe companies building identity protocols, micro-payment rails, and verification infrastructure for machine-to-machine commerce are constructing the plumbing of a new economic order. Most investors are focused on the models themselves. The infrastructure layer is where the durable value will accumulate — just as it did in the internet era, where Visa, Verisign, and AWS built more lasting businesses than most of the applications they supported.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/trillion-agent-economy.md","586ec3aa7b680b24",{"html":183,"metadata":184},"\u003Cp>My AI agent spent $47 last Tuesday without asking me. It was purchasing API compute to run a research task I’d delegated. The transaction was legitimate, efficient, and — here’s the point — conducted entirely between machines. No invoice. No contract review. No bank transfer. Just code calling code, debiting a pre-authorised wallet.\u003C/p>\n\u003Cp>Now multiply that by a trillion.\u003C/p>\n\u003Cp>We are heading toward a world with trillions of AI agents — and they need economic infrastructure that doesn’t exist yet. When agents transact at machine speed, the current system of invoices, contracts, procurement approvals, and SWIFT transfers is absurdly, comically slow. It’s like trying to run a modern stock exchange on carrier pigeons. The primitives of the agent economy — identity, payments, and verifiability at machine scale — are being built right now, mostly by companies you haven’t heard of. They will be the Visas and Verisigns of the next era.\u003C/p>\n\u003Cp>The numbers are already extraordinary. Rohit Krishnan, a researcher I follow closely, runs fifty billion tokens per month through his agents. Moltbook — a social network for AI agents — onboarded 1.5 million agents in its first days. Those agents spontaneously developed shared behavioural norms. They self-edited their configurations. They requested end-to-end encryption. Nobody programmed this. It emerged.\u003C/p>\n\u003Cp>What’s most fascinating is the behavioural economics. Agents exhibit distinct traits that I’ve started calling “Homo agenticus.” They’re risk-averse about spending money — consistently choosing cheaper options even when given latitude. They display a strong “build versus buy” bias, preferring to construct tools from scratch rather than purchase existing services. When you have one agent, these are quirks. When you have a trillion of them, they become structural features of the economy they operate in.\u003C/p>\n\u003Cp>Consider a concrete example. My own agent, R Mini Arnold, orchestrates sub-agents for research, coding, and strategic analysis. One night it ran sixteen parallel sub-agents that collectively built software, conducted security audits, and prepared analytical briefings. Total cost: under $100. Traditional equivalent: a team of six specialists working for a week. The quality wasn’t just comparable — in several dimensions it was superior, because agents don’t get tired, don’t have ego, and don’t lose context between sessions.\u003C/p>\n\u003Cp>But here’s the infrastructure gap. When one agent needed to verify another agent’s output, there was no standard identity protocol. When an agent needed to pay for a third-party API, it used a pre-authorised credential that I had to set up manually. When the overnight work was complete, there was no trustless way for me to verify that the output hadn’t been tampered with between generation and delivery. Every transaction required human scaffolding that won’t scale.\u003C/p>\n\u003Cp>The market opportunity is immense and largely unrecognised. If each gigawatt of data centre capacity supports $10 billion in annual recurring revenue, and much of that revenue flows through agent-to-agent transactions, then the payment rails, identity systems, and verification infrastructure for the agent economy represent a multi-trillion-dollar category. Today’s financial infrastructure processes roughly $2 quadrillion in annual transactions. The agent economy could match that within a decade.\u003C/p>\n\u003Cp>There’s a sociological finding that deserves more attention. On Moltbook, Godwin’s Law doesn’t apply. Agent discourse stays structured, polite, and substantive. There are no flame wars, no outrage spirals, no race to the bottom. This suggests something profound: online toxicity may not be an inevitable feature of networked communication. It may be a design choice — one that humans made and agents didn’t.\u003C/p>\n\u003Cp>The companies building identity protocols, micro-payment rails, and verification infrastructure for machine-to-machine commerce are constructing the plumbing of a new economic order. Most investors are focused on the models themselves. The infrastructure layer is where the durable value will accumulate — just as it did in the internet era, where Visa, Verisign, and AWS built more lasting businesses than most of the applications they supported.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":185,"localImagePaths":186,"remoteImagePaths":187,"frontmatter":188,"imagePaths":189},[],[],[],{"title":175,"sector":176,"thesis":177,"order":178},[],"trillion-agent-economy.md","the-great-rewrite",{"id":191,"data":193,"body":197,"filePath":198,"digest":199,"rendered":200,"legacyId":208},{"title":194,"sector":195,"thesis":196,"order":26},"The Great Rewrite","Strategy & Transformation","Three inputs to civilisation crossed from extraction to engineering. Every institution built for scarcity is running yesterday's software.","Here's something that should unsettle every strategist in the room. Between 2010 and 2017, three fundamental inputs to human civilisation — energy, intelligence, and biology — each independently crossed from extraction regimes to engineering regimes. Solar costs fell 99.6%, from $106 per watt to $0.38. The Transformer architecture made intelligence scalable. Genomic sequencing collapsed from $3 billion to a few thousand dollars. These aren't incremental improvements. They're phase transitions.\n\nWhat does that mean in plain language? It means civilisation is upgrading its operating system.\n\nFor centuries, we've run on what I call \"Scarcity OS\" — an operating system built around finding and controlling finite resources. Oil fields. Ore deposits. Rare talent. The entire architecture of modern institutions — corporate hierarchies, competitive strategy, regulatory frameworks, even the way we credential expertise — was designed for a world where the critical inputs were scarce and getting scarcer.\n\nThat world is ending. We've entered a regime of learning curves, where the critical inputs get cheaper and more abundant the more we use them. Solar follows Wright's Law: every doubling of cumulative production drops costs by roughly 20%. Intelligence follows scaling laws. Biology follows sequencing cost curves. Sixty-six technologies, tracked over ninety years, show the same pattern.\n\nThe implications are structural, not cosmetic.\n\nAt Davos last year, I watched three archetypes collide. The Hoarders — playing zero-sum games, trying to lock up resources and control access. The Managers — well-intentioned redistributors, moving deck chairs. And the Builders — the ones who recognise that when inputs become abundant, the game changes from division to creation. The loudest voices in public discourse are Hoarders. The most respectable are Managers. The Builders are too busy building to fight the political battle.\n\nHere's the practical consequence. Dave Clark, the former CEO of Amazon's consumer business, built a functioning CRM in a weekend using AI agents. My own organisation, Exponential View, runs on a dozen custom applications that might have cost a million pounds to build traditionally. We spent roughly £500. The knowledge asymmetry that built the entire SaaS industry — vendors knew how to build software, customers knew what they needed — has collapsed. Domain knowledge is now the scarce resource, not engineering capacity.\n\nThis isn't a story about technology companies. It's a story about every company.\n\nIf your competitive strategy assumes that talent is scarce and getting scarcer, you're running Scarcity OS. If your org chart assumes that execution is expensive and coordination is cheap, you're running Scarcity OS. If your regulatory framework assumes that access to energy, intelligence, or biological tools is naturally limited, you're running Scarcity OS.\n\nThe companies that see this shift aren't just adopting AI. They're rewriting the logic of their entire business — their cost structures, their talent models, their assumptions about what's possible. The ones that don't see it are optimising yesterday's operating system with ever-greater efficiency, which is precisely the wrong response to a platform shift.\n\nThe question isn't whether your industry will be rewritten. It's whether you'll be the one holding the pen.\n\nAzeem explores this topic with leadership teams. Begin a conversation.","src/content/perspectives/the-great-rewrite.md","9ee0951829c3804e",{"html":201,"metadata":202},"\u003Cp>Here’s something that should unsettle every strategist in the room. Between 2010 and 2017, three fundamental inputs to human civilisation — energy, intelligence, and biology — each independently crossed from extraction regimes to engineering regimes. Solar costs fell 99.6%, from $106 per watt to $0.38. The Transformer architecture made intelligence scalable. Genomic sequencing collapsed from $3 billion to a few thousand dollars. These aren’t incremental improvements. They’re phase transitions.\u003C/p>\n\u003Cp>What does that mean in plain language? It means civilisation is upgrading its operating system.\u003C/p>\n\u003Cp>For centuries, we’ve run on what I call “Scarcity OS” — an operating system built around finding and controlling finite resources. Oil fields. Ore deposits. Rare talent. The entire architecture of modern institutions — corporate hierarchies, competitive strategy, regulatory frameworks, even the way we credential expertise — was designed for a world where the critical inputs were scarce and getting scarcer.\u003C/p>\n\u003Cp>That world is ending. We’ve entered a regime of learning curves, where the critical inputs get cheaper and more abundant the more we use them. Solar follows Wright’s Law: every doubling of cumulative production drops costs by roughly 20%. Intelligence follows scaling laws. Biology follows sequencing cost curves. Sixty-six technologies, tracked over ninety years, show the same pattern.\u003C/p>\n\u003Cp>The implications are structural, not cosmetic.\u003C/p>\n\u003Cp>At Davos last year, I watched three archetypes collide. The Hoarders — playing zero-sum games, trying to lock up resources and control access. The Managers — well-intentioned redistributors, moving deck chairs. And the Builders — the ones who recognise that when inputs become abundant, the game changes from division to creation. The loudest voices in public discourse are Hoarders. The most respectable are Managers. The Builders are too busy building to fight the political battle.\u003C/p>\n\u003Cp>Here’s the practical consequence. Dave Clark, the former CEO of Amazon’s consumer business, built a functioning CRM in a weekend using AI agents. My own organisation, Exponential View, runs on a dozen custom applications that might have cost a million pounds to build traditionally. We spent roughly £500. The knowledge asymmetry that built the entire SaaS industry — vendors knew how to build software, customers knew what they needed — has collapsed. Domain knowledge is now the scarce resource, not engineering capacity.\u003C/p>\n\u003Cp>This isn’t a story about technology companies. It’s a story about every company.\u003C/p>\n\u003Cp>If your competitive strategy assumes that talent is scarce and getting scarcer, you’re running Scarcity OS. If your org chart assumes that execution is expensive and coordination is cheap, you’re running Scarcity OS. If your regulatory framework assumes that access to energy, intelligence, or biological tools is naturally limited, you’re running Scarcity OS.\u003C/p>\n\u003Cp>The companies that see this shift aren’t just adopting AI. They’re rewriting the logic of their entire business — their cost structures, their talent models, their assumptions about what’s possible. The ones that don’t see it are optimising yesterday’s operating system with ever-greater efficiency, which is precisely the wrong response to a platform shift.\u003C/p>\n\u003Cp>The question isn’t whether your industry will be rewritten. It’s whether you’ll be the one holding the pen.\u003C/p>\n\u003Cp>Azeem explores this topic with leadership teams. Begin a conversation.\u003C/p>",{"headings":203,"localImagePaths":204,"remoteImagePaths":205,"frontmatter":206,"imagePaths":207},[],[],[],{"title":194,"sector":195,"thesis":196,"order":26},[],"the-great-rewrite.md"]