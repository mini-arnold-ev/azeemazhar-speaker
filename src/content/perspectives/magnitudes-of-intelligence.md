---
title: "The Magnitudes of Intelligence"
sector: "Productivity & AI"
thesis: "Each order of magnitude in AI token usage transforms the technology's nature — from toy to colleague to workforce."
order: 6
---

In 2022, I consumed about 1,000 AI tokens a day. It felt like a toy — a clever autocomplete that occasionally surprised me. By mid-2025, I was at a million tokens daily. AI had become a colleague: drafting, researching, challenging my assumptions. In February 2026, I hit 97,045,322 tokens in a single day. Cost: under $100. At that scale, AI isn't a tool or a colleague. It's a workforce.

Like the Eames' famous film *Powers of Ten*, adding a zero doesn't just mean "more." It changes what kind of thing you're looking at. A cell is not a small organ. A galaxy is not a large solar system. And AI at a hundred million tokens is not a faster chatbot. We're dealing with a fundamentally different relationship between human judgment and machine execution.

Here's what a hundred million tokens looks like in practice. I have an AI agent called R Mini Arnold — named, with appropriate self-deprecation, after me. While I sleep, it orchestrates sub-agents that research market data, write analysis, build software, and prepare briefings. It produced 83,302 words of output in that single day. It wrote code, deployed applications, ran security audits, and flagged items requiring my judgment in the morning. The overnight work would have taken a team of analysts and developers days. It cost less than dinner for two.

But the most important finding isn't the productivity gain. It's the paradox that comes with it.

At Spotify, the company's top developers haven't written a line of code since December 2025. They use an internal system called "Honk," built on Claude Code, which generates and tests software on its own. The engineers review AI output on their phones during their morning commute. This sounds like leisure. It isn't. We're watching the rise of invisible cognitive work — reviewing AI-generated output requires sustained, high-context judgment, the equivalent of an editor rather than a writer. It's harder, not easier. We just can't see it.

Research from UC Berkeley confirms the pattern: AI augmentation increases productivity *and* voluntary workload at the same time. Workers don't use the time savings to rest. We absorb more tasks. The scope of work expands faster than the tools compress time. I call this silent workload creep — and it may be the hidden cost of AI adoption that no organisation is yet measuring. We don't have good instruments for it yet.

A study in *The Lancet* tracked doctors using AI-assisted colonoscopy detection. With AI, their detection rate was 28.4%. When the hospital withdrew the AI, it fell to 22.4% — below their pre-AI baseline. The doctors hadn't just delegated to the machine. They'd lost the underlying skill. This is the "use it or lose it" problem at civilisational scale. If AI handles the routine, and routine practice is how expertise develops, what happens to the pipeline of future experts? We haven't answered that question.

METR's forecasting models predict near-full automation of AI research and development by 2032. Sixteen AI agents built a C++ compiler — the kind of project that traditionally requires millions of pounds and years of engineering — for $20,000. AI already generates more words per month than all humans combined; that threshold crossed in summer 2025.

These aren't projections. They're measurements.

The bottleneck at each magnitude isn't capability — models are already extraordinarily capable. The bottleneck is trust. At a thousand tokens, people trust AI to finish their sentences. At a million, they trust it to draft their emails. At a hundred million, leaders trust it to run entire operations overnight. Each jump means letting go of something once considered essential — competence, judgment, identity. Most organisations haven't worked out how to make that leap deliberately.

The organisations that scale successfully through these magnitudes will be the ones that redesign not just their workflows but their whole idea of what human work is. The role might shift from execution to judgment, from production to curation, from doing to deciding what's worth doing. That's a more demanding job, not a less demanding one. We haven't yet built the management frameworks it calls for.

The question isn't whether AI will reach the next order of magnitude. It's whether we'll be ready when it does.

Azeem explores this topic with leadership teams. Begin a conversation.
